import os
import pandas as pd
from langchain_core.documents import Document
from langchain_community.vectorstores.faiss import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings

print("ğŸ“¦ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì‹œì‘")

# 1) CSV ê²½ë¡œ ë¡œë“œ
csv_path = "data/final.csv"
print(f"ğŸ” CSV ë¡œë”© ì¤‘: {csv_path}")
df = pd.read_csv(csv_path, encoding="utf-8")

# 2) ë‚ ì§œ íƒ€ì… ë³€í™˜
print("ğŸ“… ë‚ ì§œ íƒ€ì…ìœ¼ë¡œ ë³€í™˜ ì¤‘")
df["sale_date"] = pd.to_datetime(df["sale_date"])

# 3) í…ìŠ¤íŠ¸ ìƒì„± (ì‹œê°„ í¬í•¨)
print("ğŸ§¾ í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ (ì‹œê°„ í¬í•¨)")
df["text"] = df.apply(
    lambda row: f"{row['sale_date']}ì— '{row['goods_name']}'({row['sub_name']})ì´ {row['sale_amount']}ê°œ íŒë§¤ë˜ì—ˆìŠµë‹ˆë‹¤.",
    axis=1,
)

# 4) ë‚ ì§œë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ ë¬¸ì„œ ìƒì„±
print("ğŸ“š ë‚ ì§œë³„ë¡œ ë¬¸ì„œ ê·¸ë£¹í•‘ ì¤‘")
grouped = df.groupby(df["sale_date"].dt.date)

docs = []
for date, group in grouped:
    full_text = "\n".join(group["text"].tolist())
    docs.append(Document(page_content=full_text))
print(f"âœ… ì´ {len(docs)}ê°œì˜ ë‚ ì§œë³„ ë¬¸ì„œ ìƒì„± ì™„ë£Œ")

# 5) í…ìŠ¤íŠ¸ ë¶„í• 
print("âœ‚ï¸ ë¬¸ì„œ ë¶„í•  ì¤‘")
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
split_docs = text_splitter.split_documents(docs)
print(f"âœ… ë¶„í• ëœ ë¬¸ì„œ ìˆ˜: {len(split_docs)}")

# 6) ì„ë² ë”© ë° FAISS ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
print("ğŸ§  ë²¡í„° ì„ë² ë”© ì¤‘ (ëª¨ë¸: bge-m3)")
embeddings = OllamaEmbeddings(model="bge-m3")
vectorstore = FAISS.from_documents(split_docs, embedding=embeddings)

# 7) ì €ì¥
print("ğŸ’¾ ë²¡í„°ìŠ¤í† ì–´ ì €ì¥ ì¤‘: vectorstore/index")
os.makedirs("vectorstore", exist_ok=True)
vectorstore.save_local("vectorstore/index")

print("ğŸ‰ âœ… ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ë° ì €ì¥ ì™„ë£Œ!")
